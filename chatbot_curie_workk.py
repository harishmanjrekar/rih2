# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPs20RRtGGxfJlpE-qY3ow0KMeULmWOz
"""

!pip install transformers
!pip install sentence_transformers

"""# New Section"""

!pip install pyodbc
!pip install openai

from transformers import BertForQuestionAnswering, BertTokenizer
import torch
import pyodbc
import openai

# Load the pre-trained BERT model and tokenizer
model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'
model = BertForQuestionAnswering.from_pretrained(model_name)
tokenizer = BertTokenizer.from_pretrained(model_name)

!lsb_release -a
!apt-get install -y curl gnupg

!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -

!curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list > /etc/apt/sources.list.d/mssql-release.list

!apt-get update

!ACCEPT_EULA=Y apt-get -y install msodbcsql18

# Connect to the database
mydb = pyodbc.connect(


  Driver="ODBC Driver 18 for SQL Server",
  Server="tcp:rih1.database.windows.net,1433",
  Database="rih",
  User="rih",
  Pwd="Adminpassword!",
  Encrypt="yes",
  TrustServerCertificate="no"
)

# Create a cursor object
cursor = mydb.cursor()

def split_context(context, max_length):
    # Split a long context into smaller chunks of maximum length
    context_chunks = []
    words = context.split()
    chunk = ""
    for word in words:
        if len(chunk) + len(word) + 1 <= max_length:  # Add 1 for the space
            chunk += word + " "
        else:
            context_chunks.append(chunk.strip())
            chunk = word + " "
    context_chunks.append(chunk.strip())
    return context_chunks

def generate_answer(question, contexts):
    top_answer = None
    top_score = 0.0

    for context in contexts:
        if len(context) > 512:
            # Split long context into smaller chunks
            context_chunks = split_context(context, max_length=512)
            context_answers = []

            for chunk in context_chunks:
                inputs = tokenizer.encode_plus(question, chunk, return_tensors='pt', max_length=512, truncation=True)
                outputs = model(**inputs)
                start_scores = outputs.start_logits
                end_scores = outputs.end_logits
                start_index = torch.argmax(start_scores)
                end_index = torch.argmax(end_scores)
                input_ids = inputs['input_ids'].tolist()[0]
                tokens = tokenizer.convert_ids_to_tokens(input_ids)
                answer = tokenizer.decode(input_ids[start_index:end_index + 1])
                score = start_scores[0, start_index] + end_scores[0, end_index]
                context_answers.append((answer, score))

            # Select the best answer from all chunks of the context
            answer, score = max(context_answers, key=lambda x: x[1])
        else:
            inputs = tokenizer.encode_plus(question, context, return_tensors='pt', max_length=512, truncation=True)
            outputs = model(**inputs)
            start_scores = outputs.start_logits
            end_scores = outputs.end_logits
            start_index = torch.argmax(start_scores)
            end_index = torch.argmax(end_scores)
            input_ids = inputs['input_ids'].tolist()[0]
            tokens = tokenizer.convert_ids_to_tokens(input_ids)
            answer = tokenizer.decode(input_ids[start_index:end_index + 1])
            score = start_scores[0, start_index] + end_scores[0, end_index]

        if score > top_score:
            top_score = score
            top_answer = answer

    if (top_answer) and (top_score > 7):
        return [top_answer]
    else:
        return None

def chatbot(question):
    # Fetch contexts from the Azure SQL database
    cursor.execute("SELECT answer FROM conversations")
    contexts = [row[0] for row in cursor.fetchall()]

    answers = generate_answer(question, contexts)
    if answers:
        return answers[0]
    else:
        return response_get_save(question)

#OPENAI_API_KEY = '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'
OPENAI_API_KEY = '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'

import os
import openai

openai.api_key =  OPENAI_API_KEY

# Define a function to save a conversation to the MySQL database
def save_conversation(question, answer):
    mycursor = mydb.cursor()
    sql = "INSERT INTO conversations (question, answer) VALUES (?, ?)"
    val = (question, answer)
    mycursor.execute(sql,val)
    #mycursor.execute("INSERT INTO conversations (question, answer) VALUES (?, ?)",question , answer)
    mydb.commit()
    print("Conversation saved to database")

def get_response(prompt):
    response = openai.Completion.create(
        engine="text-davinci-003",
        #engine="ada",
        prompt=prompt,
        max_tokens=200,
        n=1,
        stop=None,
        temperature=0.4,
    )
    return response.choices[0].text.strip()

def response_get_save(question):
        answer = get_response(question)
        save_conversation(question, answer)
        return answer

question = "Where do Ostrich live?"
answer = chatbot(question)
print(answer)